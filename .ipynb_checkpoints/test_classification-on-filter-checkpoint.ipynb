{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653eef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import skimage.filters as skfilter\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c41eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791f2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4d42abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hibiki/miniforge3/envs/my-env/lib/python3.9/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "train_dir = 'train'\n",
    "test_dir = 'test'\n",
    "\n",
    "\n",
    "def open_image(image):\n",
    "    \n",
    "    tmp_im_custom = image[0]\n",
    "    \n",
    "    for j in range(1, len(image)):\n",
    "        tmp_im_custom = np.append(tmp_im_custom, image[j])\n",
    "        \n",
    "    return tmp_im_custom\n",
    "\n",
    "def get_data(dir_name):\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for emotion in ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']:\n",
    "        \n",
    "\n",
    "        for file_name in os.listdir('./archive-1/'+str(dir_name)+'/'+str(emotion)):\n",
    "\n",
    "            tmp_im = np.array(Image.open('./archive-1/'+str(dir_name)+'/'+str(emotion)+'/'+str(file_name)))\n",
    "            \n",
    "            #tmp_im_custom = open_image(tmp_im)\n",
    "            \n",
    "            x.append(tmp_im)\n",
    "            \n",
    "            #x.append(tmp_im_custom)\n",
    "\n",
    "            y.append(emotion)\n",
    "            \n",
    "    y_custom = LabelEncoder().fit_transform(np.array(y).reshape(-1,1))\n",
    "           \n",
    "    return x, y_custom\n",
    "\n",
    "\n",
    "\n",
    "train_raw_x, train_raw_y = get_data(train_dir)\n",
    "\n",
    "test_raw_x, test_raw_y = get_data(test_dir)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b7455a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "318f6c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "\n",
    "filter_name = [\"sobel\", \"scharr\", \"prewitt\", \"roberts\"]\n",
    "filter_inst = [skfilter.sobel, skfilter.scharr, skfilter.prewitt, skfilter.roberts]\n",
    "\n",
    "\n",
    "filtered_images_train = []\n",
    "filtered_images_test = []\n",
    "\n",
    "def use_filters(image_data, filt):\n",
    "    \n",
    "    filtered = []\n",
    "    \n",
    "    for image in image_data:\n",
    "        \n",
    "        filt_image = filt(image)\n",
    "        filtered.append(filt_image)\n",
    "        \n",
    "    return filtered\n",
    "\n",
    "\n",
    "for filt in filter_inst:\n",
    "    \n",
    "    filtered_images_train.append(use_filters(train_raw_x, filt))\n",
    "    filtered_images_test.append(use_filters(test_raw_x, filt))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10e41ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(filtered_images_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c77ca6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_x = deepcopy(train_raw_x)\\ntest_x = deepcopy(test_raw_x)\\n\\nfor train_array, test_array in zip(filtered_images_train, filtered_images_test):\\n    \\n    train_x = np.concatenate([train_x, train_array])\\n    test_x = np.concatenate([test_x, test_array])\\n    \\n    \\ntrain_y = deepcopy(train_raw_y)\\ntest_y = deepcopy(test_raw_y)\\n\\nfor i in range(len(filter_inst)):\\n    train_y = np.concatenate([train_y, train_raw_y])\\n    test_y = np.concatenate([test_y, test_raw_y])\\n    \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_x = []\n",
    "test_x = []\n",
    "\n",
    "train_x.append(deepcopy(train_raw_x))\n",
    "test_x.append(deepcopy(test_raw_x))\n",
    "\n",
    "for train_array, test_array in zip(filtered_images_train, filtered_images_test):\n",
    "    \n",
    "    train_x.append(train_array)\n",
    "    test_x.append(test_array)\n",
    "    \n",
    "    \n",
    "train_y = deepcopy(train_raw_y)\n",
    "test_y = deepcopy(test_raw_y)\n",
    "\n",
    "\n",
    "\"\"\"train_x = deepcopy(train_raw_x)\n",
    "test_x = deepcopy(test_raw_x)\n",
    "\n",
    "for train_array, test_array in zip(filtered_images_train, filtered_images_test):\n",
    "    \n",
    "    train_x = np.concatenate([train_x, train_array])\n",
    "    test_x = np.concatenate([test_x, test_array])\n",
    "    \n",
    "    \n",
    "train_y = deepcopy(train_raw_y)\n",
    "test_y = deepcopy(test_raw_y)\n",
    "\n",
    "for i in range(len(filter_inst)):\n",
    "    train_y = np.concatenate([train_y, train_raw_y])\n",
    "    test_y = np.concatenate([test_y, test_raw_y])\n",
    "    \n",
    "\"\"\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0623598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling\n",
    "\n",
    "\n",
    "def harf_mean_pooling(image):\n",
    "    \n",
    "    means = []\n",
    "    \n",
    "    for hori in range(len(image)//2):\n",
    "        for ver in range(len(image[0])//2):\n",
    "        \n",
    "            mean = np.mean(image[hori:hori+len(image)//2][ver:ver+len(image)//2])\n",
    "\n",
    "            means.append(mean)\n",
    "        \n",
    "    return means\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07f3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f962de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for train in train_x:\\n    \\n    train_x_use.append(harf_mean_pooling(train))\\n    \\n    \\nfor test in test_x:\\n    test_x_use.append(harf_mean_pooling(test))\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_x_use = []\n",
    "test_x_use = []\n",
    "\n",
    "\n",
    "# normal\n",
    "for train in train_x:\n",
    "    tmp_train = []\n",
    "\n",
    "    for image in train:\n",
    "        \n",
    "        tmp_train.append(open_image(image))\n",
    "    train_x_use.append(tmp_train)\n",
    "    \n",
    "    \n",
    "for test in test_x:\n",
    "    tmp_test = []\n",
    "    for image in test:\n",
    "        tmp_test.append(open_image(image))\n",
    "        \n",
    "    test_x_use.append(tmp_test)\n",
    "\n",
    "\n",
    "# mean pooling\n",
    "\"\"\"for train in train_x:\n",
    "    \n",
    "    train_x_use.append(harf_mean_pooling(train))\n",
    "    \n",
    "    \n",
    "for test in test_x:\n",
    "    test_x_use.append(harf_mean_pooling(test))\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4cdeb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 28709, 2304)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_x_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b32b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model\n",
    "\n",
    "\n",
    "model_sobel = lgb.LGBMClassifier(verbose=1)\n",
    "model_scharr = lgb.LGBMClassifier(verbose=1)\n",
    "model_prewitt = lgb.LGBMClassifier(verbose=1)\n",
    "model_roberts = lgb.LGBMClassifier(verbose=1)\n",
    "model_raw = lgb.LGBMClassifier(verbose=1)\n",
    "\n",
    "models = [model_sobel, model_scharr, model_prewitt, model_roberts, model_raw]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e6b920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.359647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 552538\n",
      "[LightGBM] [Info] Number of data points in the train set: 28709, number of used features: 2304\n",
      "[LightGBM] [Info] Start training from score -1.972167\n",
      "[LightGBM] [Info] Start training from score -4.187324\n",
      "[LightGBM] [Info] Start training from score -1.946956\n",
      "[LightGBM] [Info] Start training from score -1.381048\n",
      "[LightGBM] [Info] Start training from score -1.754797\n",
      "[LightGBM] [Info] Start training from score -1.782364\n",
      "[LightGBM] [Info] Start training from score -2.203164\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "\n",
    "for model, train_data in zip(models, train_x_use):\n",
    "    \n",
    "    model.fit(train_data, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b417eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "preds = []\n",
    "\n",
    "for model, test_data in zip(models, test_x_use):\n",
    "    pred = model.predict(test_data)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.append(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds\n",
    "\n",
    "df_columns = filter_name + [\"raw\", \"ans\"]\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame(np.array(preds).T, columns=df_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.loc[:, filter_name+[\"raw\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.mode(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "07ae3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mode_df = pred_df.loc[:, filter_name+[\"ans\"]].mode(axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "07284075",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_df.columns = filter_name+[\"raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "6070e642",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-675db53f1f9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mans_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "np.any(mode_df.loc[0, :].values == ans_num[\"ans\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f53a5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "\n",
    "for i in range(len(pred_df[\"ans\"])):\n",
    "    \n",
    "    if np.any(mode_df.loc[i, :].values == pred_df[\"ans\"][i]):\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "2fd16e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5923655614377263"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count / len(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "12b4aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval score\n",
    "\n",
    "c = 0\n",
    "\n",
    "for i in range(len(test_x_use)):\n",
    "    if test_y[i] == pred[i]:\n",
    "        c += 1\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ba6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7d40a2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10567857142857143"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c/(len(test_x_use))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "034edd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: | \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "                                                                               failed\n",
      "\n",
      "UnsatisfiableError: The following specifications were found to be incompatible with each other:\n",
      "\n",
      "Output in format: Requested package -> Available versions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17947d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
